<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><script>!function(){try {var d=document.documentElement.classList;d.remove('light','dark');var e=localStorage.getItem('theme');d.add('light');if("system"===e||(!e&&false)){var t="(prefers-color-scheme: dark)",m=window.matchMedia(t);m.media!==t||m.matches?d.add('dark'):d.add('light')}else if(e) d.add(e)}catch(e){}}()</script><meta content="width=device-width, initial-scale=1" name="viewport"/><title>Running an AMD Instinct MI50 on a LattePanda Mu Lite (OCuLink eGPU) for Local LLMs | Smart Home Circle</title><meta name="robots" content="follow, index"/><meta name="description" content="Step-by-step AMD Instinct MI50 eGPU on LattePanda Mu Lite carrier board: Ubuntu 24.04 HWE, ROCm, Vulkan, Ollama &amp; llama.cpp on GPU, PCIe/OCuLink"/><meta property="og:url" content="https://smarthomecircle.com/run-gpu-on-latte-panda-mu-lite-carrier-board"/><meta property="og:type" content="article"/><meta property="og:site_name" content="Smart Home Circle"/><meta property="og:description" content="Step-by-step AMD Instinct MI50 eGPU on LattePanda Mu Lite carrier board: Ubuntu 24.04 HWE, ROCm, Vulkan, Ollama &amp; llama.cpp on GPU, PCIe/OCuLink"/><meta property="og:title" content="Running an AMD Instinct MI50 on a LattePanda Mu Lite (OCuLink eGPU) for Local LLMs"/><meta property="og:image" content="https://smarthomecircle.com/static/images/2025/gpu-experiment/cover.webp"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="https://twitter.com/smarthomecircle"/><meta name="twitter:title" content="Running an AMD Instinct MI50 on a LattePanda Mu Lite (OCuLink eGPU) for Local LLMs"/><meta name="twitter:description" content="Step-by-step AMD Instinct MI50 eGPU on LattePanda Mu Lite carrier board: Ubuntu 24.04 HWE, ROCm, Vulkan, Ollama &amp; llama.cpp on GPU, PCIe/OCuLink"/><meta name="twitter:image" content="https://smarthomecircle.com/static/images/2025/gpu-experiment/cover.webp"/><meta property="article:published_time" content="2025-11-13T00:00:00.000Z"/><link rel="canonical" href="https://smarthomecircle.com/run-gpu-on-latte-panda-mu-lite-carrier-board"/><meta name="next-head-count" content="19"/><link rel="apple-touch-icon" sizes="76x76" href="/static/favicons/icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/static/favicons/icon.png"/><link rel="icon" type="image/png" sizes="16x16" href="/static/favicons/icon.png"/><link rel="manifest" href="/static/favicons/site.webmanifest"/><meta name="msapplication-TileColor" content="#000000"/><meta name="theme-color" content="#000000"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7490174059724719" crossorigin="anonymous"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/98fc8f77fedfbe0a.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/98fc8f77fedfbe0a.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d91f4f98d5458a38.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-813e4218627b5a82.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-9948ba1951d3eeac.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/146-6e5e503440377105.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/158-8fd8e2b305180da3.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/%5Bslug%5D-f49d9f6c4e8bed79.js" defer="" crossorigin=""></script><script src="/_next/static/si5NwbjYRJRZuz5hjmIr6/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/si5NwbjYRJRZuz5hjmIr6/_ssgManifest.js" defer="" crossorigin=""></script><style data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap">@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=UcCO3FwrK3iLTeHuS_nVMrMxCp50SjIw2boKoduKmMEVuLyfMZs&skey=c491285d6722e4fa&v=v20) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=UcCO3FwrK3iLTeHuS_nVMrMxCp50SjIw2boKoduKmMEVuI6fMZs&skey=c491285d6722e4fa&v=v20) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=UcCO3FwrK3iLTeHuS_nVMrMxCp50SjIw2boKoduKmMEVuGKYMZs&skey=c491285d6722e4fa&v=v20) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=UcCO3FwrK3iLTeHuS_nVMrMxCp50SjIw2boKoduKmMEVuFuYMZs&skey=c491285d6722e4fa&v=v20) format('woff')}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=tDbY2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKxjPg&skey=48ad01c60053c2ae&v=v24) format('woff')}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=tDbY2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8-qxjPg&skey=48ad01c60053c2ae&v=v24) format('woff')}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=tDbY2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8FqtjPg&skey=48ad01c60053c2ae&v=v24) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v20/UcC73FwrK3iLTeHuS_nVMrMxCp50SjIa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPx3cwgknk-6nFg.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPxTcwgknk-6nFg.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPxPcwgknk-6nFg.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPx_cwgknk-6nFg.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPx7cwgknk-6nFg.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPxDcwgknk-4.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPx3cwgknk-6nFg.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPxTcwgknk-6nFg.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPxPcwgknk-6nFg.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPx_cwgknk-6nFg.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPx7cwgknk-6nFg.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPxDcwgknk-4.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPx3cwgknk-6nFg.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPxTcwgknk-6nFg.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPxPcwgknk-6nFg.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPx_cwgknk-6nFg.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPx7cwgknk-6nFg.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'JetBrains Mono';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/jetbrainsmono/v24/tDbv2o-flEEny0FZhsfKu5WU4zr3E_BX0PnT8RD8yKwBNntkaToggR7BYRbKPxDcwgknk-4.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body class="antialiased text-gray-700 bg-white dark:bg-gray-900 dark:text-gray-300 font-sans"><div id="__next"><div class="max-w-3xl px-4 mx-auto sm:px-6 xl:max-w-6xl xl:px-0"><div class="flex flex-col justify-between h-screen"><header class="flex items-center justify-between py-10"><div><a aria-label="SmartHomeCircle" href="/"><div class="flex items-center"><div class="mr-3"><img alt="smart home circle" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" style="color:transparent" src="/static/favicons/icon.png"/></div><div class="text-2xl font-semibold sm:block">Smart Home Circle</div></div></a></div><div class="mt-6"></div><div class="flex items-center text-base leading-5"><div class="hidden sm:flex items-center"><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/@SmartHomeCircle" class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100">YouTube</a><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/tags">Tags</a><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/posts">Posts</a><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/about">About &amp; Contact</a><a target="_blank" rel="noopener noreferrer" href="https://www.buymeacoffee.com/amrutprabhu"><img alt="Buy Me A Coffee" loading="lazy" width="140" height="20" decoding="async" data-nimg="1" style="color:transparent" src="static/buymeacoffee.png"/></a></div><button aria-label="Toggle Dark Mode" type="button" class="w-8 h-8 p-1 ml-1 mr-1 rounded sm:ml-4"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path></svg></button><div class="sm:hidden"><button type="button" class="w-8 h-8 py-1 ml-1 mr-1 rounded" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div class="fixed w-full h-full top-24 right-0 bg-gray-200 dark:bg-gray-800 opacity-95 z-10 transform ease-in-out duration-300 translate-x-full"><button type="button" aria-label="toggle modal" class="fixed w-full h-full cursor-auto focus:outline-none"></button><nav class="fixed h-full mt-8"><div class="px-12 py-4"><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/@SmartHomeCircle" class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100">YouTube</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/tags">Tags</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/posts">Posts</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/about">About &amp; Contact</a></div><div class="px-12 py-4"><a target="_blank" rel="noopener noreferrer" href="https://www.buymeacoffee.com/amrutprabhu"><img alt="Buy Me A Coffee" loading="lazy" width="140" height="20" decoding="async" data-nimg="1" style="color:transparent" src="static/buymeacoffee.png"/></a></div></nav></div></div></div></header><main class="mb-auto"><div class="max-w-3xl px-4 mx-auto sm:px-6 xl:max-w-6xl xl:px-0"><div class="fixed flex-col hidden gap-3 right-8 bottom-8 md:flex"><button aria-label="Scroll To Top" type="button" style="opacity:0" class="p-2 text-gray-500 transition-all bg-gray-200 rounded-full dark:text-gray-400 dark:bg-gray-700 dark:hover:bg-gray-600 hover:bg-gray-300"><svg class="w-5 h-5" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z" clip-rule="evenodd"></path></svg></button></div><article><header class="relative"><div class="absolute inset-0 bg-gradient-to-br from-gray-50 via-white to-primary-50 dark:from-gray-900 dark:via-gray-900 dark:to-primary-900/20 -z-10"></div><div class="relative pt-12 pb-16"><div class="flex items-center justify-center mb-6"><a class="inline-flex items-center text-sm font-medium text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 transition-colors" href="/"><svg class="w-4 h-4 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg>Blog Article</a></div><div class="max-w-4xl mx-auto text-center space-y-6"><h1 class="text-4xl md:text-5xl lg:text-6xl font-bold text-gray-900 dark:text-gray-100 leading-tight">Running an AMD Instinct MI50 on a LattePanda Mu Lite (OCuLink eGPU) for Local LLMs</h1><div class="flex flex-wrap items-center justify-center gap-6 text-sm text-gray-600 dark:text-gray-300"><div class="flex items-center"><svg class="w-4 h-4 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path></svg><time dateTime="2025-11-13T00:00:00.000Z">Thursday, November 13, 2025</time></div><div class="flex items-center"><svg class="w-4 h-4 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>5 min read</div></div></div><div class="max-w-5xl mx-auto mt-12"><div class="relative overflow-hidden rounded-2xl shadow-2xl"><div class="absolute inset-0 bg-gradient-to-t from-black/10 via-transparent to-transparent z-10"></div><img alt="Running an AMD Instinct MI50 on a LattePanda Mu Lite (OCuLink eGPU) for Local LLMs" loading="lazy" width="800" height="450" decoding="async" data-nimg="1" class="object-cover object-center w-full h-auto" style="color:transparent" src="/static/images/2025/gpu-experiment/cover.webp"/></div></div></div></header><div class="max-w-6xl mx-auto px-4 py-16"><div class="lg:grid lg:grid-cols-12 lg:gap-8"><div class="lg:col-span-8"><div class="mb-12 p-6 bg-gray-50 dark:bg-gray-800/50 rounded-2xl border border-gray-200 dark:border-gray-700"><h3 class="text-sm font-semibold text-gray-500 dark:text-gray-400 uppercase tracking-wide mb-4">Written by</h3><div class="flex items-center space-x-4"><div class="flex items-center space-x-3"><img alt="Amrut Prabhu avatar" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="w-12 h-12 rounded-full ring-2 ring-white dark:ring-gray-700" style="color:transparent" src="/static/images/avatar-small.jpg"/><div><div class="font-semibold text-gray-900 dark:text-gray-100">Amrut Prabhu</div><a target="_blank" rel="noopener noreferrer" href="https://twitter.com/smarthomecircle" class="text-sm text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 transition-colors">@smarthomecircle</a></div></div></div></div><div class="mb-12 space-y-8"><h3 class="text-lg font-semibold text-gray-900 dark:text-gray-100">Featured Video</h3><div class="relative w-full rounded-2xl overflow-hidden shadow-lg" style="padding-bottom:56.25%"><iframe id="youtubeLink12025-11-13T00:00:00.000Z" class="absolute top-0 left-0 w-full h-full" src="https://www.youtube.com/embed/iXYsRK_gqTA" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" title="Featured video player"></iframe></div></div><div class="prose prose-lg dark:prose-dark max-w-none prose-headings:font-bold prose-headings:text-gray-900 dark:prose-headings:text-gray-100 prose-p:text-gray-700 dark:prose-p:text-gray-300 prose-strong:text-gray-900 dark:prose-strong:text-gray-100 prose-code:text-primary-600 dark:prose-code:text-primary-400 prose-pre:bg-gray-900 dark:prose-pre:bg-gray-800 prose-blockquote:border-primary-500 prose-blockquote:text-gray-700 dark:prose-blockquote:text-gray-300"><details open=""><summary class="pt-2 pb-2 ml-6 text-xl font-bold">Table of Contents</summary><div class="ml-6"><ul><li class="false"><a href="#hardware--topology-i-used">Hardware &amp; Topology I Used</a></li><li class="false"><a href="#os-install--first-detection">OS Install &amp; First Detection</a></li><li class="false"><a href="#install-the-ubuntu-hwe-kernel-recommended-before-amd-drivers">Install the Ubuntu HWE kernel (recommended, before AMD drivers)</a></li><li class="false"><a href="#amd-driver--rocm-what-actually-worked">AMD Driver + ROCm: What Actually Worked</a></li><li class="ml-6"><a href="#install-the-amd-driver-installer-702-then-rocm">Install the AMD driver installer 7.0.2, then ROCm</a></li><li class="false"><a href="#ollama-with-amd-rocm">Ollama with AMD ROCm</a></li><li class="false"><a href="#building-llamacpp-for-amd-rocm-hip">Building llama.cpp for AMD ROCm (HIP)</a></li><li class="false"><a href="#running-a-model-with-llamacpp-on-rocm">Running a Model with llama.cpp on ROCm</a></li><li class="ml-6"><a href="#token-statistics">Token statistics</a></li><li class="false"><a href="#building--running-with-vulkan-no-rocm-needed">Building &amp; Running with Vulkan (No ROCm Needed)</a></li><li class="ml-6"><a href="#install-vulkan-runtime--dev-bits">Install Vulkan runtime + dev bits</a></li><li class="ml-6"><a href="#build-llamacpp-with-vulkan">Build llama.cpp with Vulkan</a></li><li class="ml-6"><a href="#run-llama-cli-with-vulkan">Run llama-cli with Vulkan</a></li><li class="ml-6"><a href="#token-statistics">Token statistics</a></li></ul></div></details>
<p>I’ve been tinkering with a <strong>LattePanda Mu Lite</strong> and an <strong>AMD Instinct MI50 (16 GB HBM2)</strong> in an <strong>eGPU</strong> setup over <strong>OCuLink</strong>. My end-goals: run <strong>Ollama</strong> and <strong>llama.cpp</strong> with GPU acceleration on <strong>Ubuntu 24.04 LTS</strong>.</p>
<p>This is my living log: everything I did, what worked, and the exact commands I used—warts and all. I’m writing it as a first‑person guide so you can follow (or avoid) my footsteps.</p>
<hr/>
<h2 id="hardware--topology-i-used"><a href="#hardware--topology-i-used" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Hardware &amp; Topology I Used</h2>
<ul>
<li><strong>Host:</strong> <strong>LattePanda Mu Lite</strong> carrier board, Ubuntu <strong>24.04.1 LTS</strong> (kernel was <code>6.14.0-33-generic</code> in my case)</li>
</ul>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/latte-panda-mu.webp" alt="vulkan eval"/></div>
<div class="border-l-4 border-primary-500 bg-primary-50 dark:bg-primary-900/20 pl-4 pr-3 py-1 my-3 rounded-r-lg"><div class="flex flex-col sm:flex-row sm:items-center gap-1.5"><p class="text-sm font-medium text-gray-900 dark:text-gray-100">Latte Panda Mu Lite Carrier Board<!-- -->:</p><div class="flex flex-wrap gap-1.5"><a href="https://amzn.to/4qQevai" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-2 py-1 bg-white dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded text-sm font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors"><svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg>Amazon DE</a><a href="https://amzn.to/3WLJS88" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-2 py-1 bg-white dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded text-sm font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors"><svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg>Amazon US</a></div></div></div>
<ul>
<li><strong>GPU:</strong> AMD <strong>Instinct MI50</strong> (gfx906, 16 GB HBM2, passive)</li>
</ul>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/amd-instinct-mi50.webp" alt="Amd instinct mi50"/></div>
<ul>
<li><strong>eGPU + Oculink cable:</strong></li>
</ul>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/egpu.jpg" alt="vulkan eval"/></div>
<div class="border-l-4 border-primary-500 bg-primary-50 dark:bg-primary-900/20 pl-4 pr-3 py-1 my-3 rounded-r-lg"><div class="flex flex-col sm:flex-row sm:items-center gap-1.5"><p class="text-sm font-medium text-gray-900 dark:text-gray-100">eGPU Mount with Oculink Cable<!-- -->:</p><div class="flex flex-wrap gap-1.5"><a href="https://s.click.aliexpress.com/e/_c3Gutyd1" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-2 py-1 bg-white dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded text-sm font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors"><svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg>AliExpress</a><a href="https://amzn.to/4nEnY1v" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-2 py-1 bg-white dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded text-sm font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors"><svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg>Amazon US</a><a href="https://amzn.to/43mrXbU" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-2 py-1 bg-white dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded text-sm font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors"><svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg>Amazon DE</a></div></div></div>
<p><strong>Connection :</strong> Mu Lite <strong>PCIe x4</strong> slot → <strong>OCuLink</strong> host adapter → OCuLink cable → x16 eGPU riser/backplane → <strong>MI50</strong></p>
<ul>
<li><strong>PCIE 4X to Oculink SFF-8612</strong></li>
</ul>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/pcie-adapter.webp" alt="PCIE 4X to Oculink SFF-8612"/></div>
<div class="border-l-4 border-primary-500 bg-primary-50 dark:bg-primary-900/20 pl-4 pr-3 py-1 my-3 rounded-r-lg"><div class="flex flex-col sm:flex-row sm:items-center gap-1.5"><p class="text-sm font-medium text-gray-900 dark:text-gray-100">PCIE 4X to Oculink SFF-8612<!-- -->:</p><div class="flex flex-wrap gap-1.5"><a href="https://s.click.aliexpress.com/e/_c3X4MKnV" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-2 py-1 bg-white dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded text-sm font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors"><svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg>AliExpress</a><a href="https://amzn.to/3JNQL61" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-2 py-1 bg-white dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded text-sm font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors"><svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg>Amazon US</a><a href="https://amzn.to/49kKVDH" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-2 py-1 bg-white dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded text-sm font-medium text-gray-700 dark:text-gray-300 hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors"><svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg>Amazon DE</a></div></div></div>
<ul>
<li><strong>Power:</strong> 12 V for the carrier (required for the on-board PCIe slot), ATX PSU for the MI50 (2× 8‑pin), <em>lots</em> of airflow through the passive heatsink</li>
</ul>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/full-setup.webp" alt="full setup"/></div>
<hr/>
<h2 id="os-install--first-detection"><a href="#os-install--first-detection" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>OS Install &amp; First Detection</h2>
<p>I did a <strong>fresh Ubuntu 24.04.1</strong> install to NVMe. After connecting the eGPU chain and powering the GPU first, I booted the Mu and SSH’d in.</p>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/ubuntu.webp" alt="ubuntu"/></div>
<p>Check that the GPU is seen on the bus:</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line">lspci <span class="token operator">|</span> <span class="token function">egrep</span> <span class="token parameter variable">-i</span> <span class="token string">&#x27;amd|ati|vega|instinct&#x27;</span>
</span><span class="code-line"><span class="token function">sudo</span> lspci <span class="token operator">|</span> <span class="token function">egrep</span> <span class="token string">&#x27;LnkCap|LnkSta&#x27;</span>
</span><span class="code-line"><span class="token comment"># I expect: Speed 8GT/s, Width x4  (PCIe 3.0 x4 over OCuLink)</span>
</span></code></pre></div>
<hr/>
<h2 id="install-the-ubuntu-hwe-kernel-recommended-before-amd-drivers"><a href="#install-the-ubuntu-hwe-kernel-recommended-before-amd-drivers" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Install the Ubuntu HWE kernel (recommended, before AMD drivers)</h2>
<p>Before installing the AMD GPU drivers/ROCm stack, I install the Ubuntu 24.04 <strong>HWE kernel</strong>. This keeps me on the supported kernel stream and ensures the extra kernel modules (like <strong>KFD</strong>) are available for my running kernel.</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token function">sudo</span> <span class="token function">apt</span> update
</span><span class="code-line"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> linux-generic-hwe-24.04
</span><span class="code-line"><span class="token function">sudo</span> <span class="token function">reboot</span>
</span></code></pre></div>
<p>If <code>/dev/kfd</code> or other modules are missing on the new kernel, I install the <strong>modules-extra</strong> package that matches the <em>running</em> kernel:</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> <span class="token string">&quot;linux-modules-extra-<span class="token variable"><span class="token variable">$(</span><span class="token function">uname</span> <span class="token parameter variable">-r</span><span class="token variable">)</span></span>&quot;</span>
</span></code></pre></div>
<h2 id="amd-driver--rocm-what-actually-worked"><a href="#amd-driver--rocm-what-actually-worked" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>AMD Driver + ROCm: What Actually Worked</h2>
<p>My goal was to get <strong>ROCm</strong> working so apps can use the GPU (<strong>/dev/kfd</strong> must exist). Here’s the exact path that worked for me.</p>
<h3 id="install-the-amd-driver-installer-702-then-rocm"><a href="#install-the-amd-driver-installer-702-then-rocm" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Install the AMD driver installer 7.0.2, then ROCm</h3>
<p>I am installed the AMD installer from the AMD <a target="_blank" rel="noopener noreferrer" href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/quick-start.html#rocm-install-quick">site</a>.</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token function">wget</span> https://repo.radeon.com/amdgpu-install/7.0.2/ubuntu/noble/amdgpu-install_7.0.2.70002-1_all.deb
</span><span class="code-line"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> ./amdgpu-install_7.0.2.70002-1_all.deb
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># install ROCm user-space + graphics, but NO DKMS</span>
</span><span class="code-line"><span class="token function">sudo</span> amdgpu-install <span class="token parameter variable">-y</span> <span class="token parameter variable">--usecase</span><span class="token operator">=</span>rocm
</span></code></pre></div>
<p>I then copied the required files as mentioned in this <a target="_blank" rel="noopener noreferrer" href="">reddit post</a></p>
<div class="relative"><pre><code class="code-highlight"><span class="code-line">1. Download the 6.4 rocblas from here: https://archlinux.org/packages/extra/x86_64/rocblas/
</span><span class="code-line">2. Extract it 
</span><span class="code-line">3. Copy all tensor files that contain gfx906 in rocblas-6.4.3-3-x86_64.pkg/opt/rocm/lib/rocblas/library to /opt/rocm/lib/rocblas/library
</span><span class="code-line">4. sudo reboot
</span></code></pre></div>
<p><em><a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/linux4noobs/comments/1ly8rq6/comment/nb9uiye/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button">source</a></em></p>
<h2 id="ollama-with-amd-rocm"><a href="#ollama-with-amd-rocm" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Ollama with AMD ROCm</h2>
<p>I installed Ollama using the command from the ollama site</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">#then started the ollama server</span>
</span><span class="code-line">ollama serve
</span></code></pre></div>
<blockquote>
<p><strong>Update:</strong>  Ollama dropped support for the <code>gfx906</code> in the <code>0.12.5</code> <a target="_blank" rel="noopener noreferrer" href="http://github.com/ollama/ollama/releases/tag/v0.12.5">release</a>. However there is an <a target="_blank" rel="noopener noreferrer" href="https://github.com/ollama/ollama/issues/12600">issue</a> created to add back the support for <code>gfx906</code></p>
</blockquote>
<p><strong>If I run it as a systemd service</strong>, I make sure the service user has device access:</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token comment"># give the &#x27;ollama&#x27; user access (if it exists)</span>
</span><span class="code-line">getent <span class="token function">passwd</span> ollama <span class="token operator">&gt;</span>/dev/null <span class="token operator">&amp;&amp;</span> <span class="token function">sudo</span> <span class="token function">usermod</span> <span class="token parameter variable">-a</span> <span class="token parameter variable">-G</span> render,video ollama
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># ensure the service gets those groups</span>
</span><span class="code-line"><span class="token function">sudo</span> <span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /etc/systemd/system/ollama.service.d
</span><span class="code-line"><span class="token builtin class-name">printf</span> <span class="token string">&quot;[Service]
</span></span><span class="code-line"><span class="token string">SupplementaryGroups=render video
</span></span><span class="code-line"><span class="token string">&quot;</span> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/systemd/system/ollama.service.d/rocm.conf
</span><span class="code-line"><span class="token function">sudo</span> systemctl daemon-reload
</span><span class="code-line"><span class="token function">sudo</span> systemctl restart ollama
</span></code></pre></div>
<p><strong>Sanity test</strong> (watch the GPU in another shell):</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line">amd-smi monitor <span class="token parameter variable">--gpu</span> <span class="token number">0</span>
</span><span class="code-line">ollama run llama3.1:8b <span class="token parameter variable">--verbose</span>
</span></code></pre></div>
<hr/>
<h2 id="building-llamacpp-for-amd-rocm-hip"><a href="#building-llamacpp-for-amd-rocm-hip" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Building llama.cpp for AMD ROCm (HIP)</h2>
<p>The supported flagset has changed over time. What worked reliably for me:</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token function">sudo</span> <span class="token function">apt</span> update
</span><span class="code-line"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> build-essential cmake ninja-build pkg-config libcurl4-openssl-dev
</span><span class="code-line">
</span><span class="code-line"><span class="token function">git</span> clone https://github.com/ggml-org/llama.cpp.git
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># from the repo root:</span>
</span><span class="code-line"><span class="token builtin class-name">cd</span> ~/llama.cpp
</span><span class="code-line"><span class="token function">rm</span> <span class="token parameter variable">-rf</span> build
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># Configure for ROCm/HIP; target MI50&#x27;s gfx906</span>
</span><span class="code-line"><span class="token assign-left variable">HIPCXX</span><span class="token operator">=</span><span class="token string">&quot;<span class="token variable"><span class="token variable">$(</span>hipconfig <span class="token parameter variable">-l</span><span class="token variable">)</span></span>/clang&quot;</span> <span class="token assign-left variable">HIP_PATH</span><span class="token operator">=</span><span class="token string">&quot;<span class="token variable"><span class="token variable">$(</span>hipconfig <span class="token parameter variable">-R</span><span class="token variable">)</span></span>&quot;</span> cmake <span class="token parameter variable">-S</span> <span class="token builtin class-name">.</span> <span class="token parameter variable">-B</span> build <span class="token parameter variable">-G</span> Ninja   <span class="token parameter variable">-DGGML_HIP</span><span class="token operator">=</span>ON   <span class="token parameter variable">-DAMDGPU_TARGETS</span><span class="token operator">=</span>gfx906   <span class="token parameter variable">-DCMAKE_BUILD_TYPE</span><span class="token operator">=</span>Release   <span class="token parameter variable">-DLLAMA_CURL</span><span class="token operator">=</span>ON   <span class="token parameter variable">-DCMAKE_PREFIX_PATH</span><span class="token operator">=</span>/opt/rocm
</span><span class="code-line">
</span><span class="code-line">cmake <span class="token parameter variable">--build</span> build -j<span class="token string">&quot;<span class="token variable"><span class="token variable">$(</span>nproc<span class="token variable">)</span></span>&quot;</span>
</span></code></pre></div>
<p><strong>How I knew it worked:</strong> on startup, <code>llama-cli</code> printed something like:</p>
<div class="relative"><pre><code class="code-highlight"><span class="code-line">ggml_cuda_init: found 1 ROCm devices:
</span><span class="code-line">  Device 0: AMD Instinct MI50/MI60, gfx906:sramecc+:xnack- ...
</span></code></pre></div>
<hr/>
<h2 id="running-a-model-with-llamacpp-on-rocm"><a href="#running-a-model-with-llamacpp-on-rocm" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Running a Model with llama.cpp on ROCm</h2>
<p>I used a <strong>Qwen3‑14B GGUF</strong> from a GGUF repository. I grabbed the new HF CLI and downloaded a <strong>Q4_K_M</strong> quant (fits in 16 GB):</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line">python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">-U</span> <span class="token string">&quot;huggingface_hub[cli]&quot;</span>
</span><span class="code-line">
</span><span class="code-line">hf download Qwen/Qwen3-14B-GGUF   <span class="token parameter variable">--include</span> <span class="token string">&quot;Qwen3-14B-Q4_K_M.gguf&quot;</span>   --local-dir ~/AI/models
</span></code></pre></div>
<p>Run it:</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token comment"># make sure compute devices exist (per boot)</span>
</span><span class="code-line"><span class="token function">sudo</span> modprobe amdgpu <span class="token operator">&amp;&amp;</span> <span class="token function">sudo</span> modprobe amdkfd
</span><span class="code-line"><span class="token function">ls</span> <span class="token parameter variable">-l</span> /dev/kfd /dev/dri/renderD*    <span class="token comment"># /dev/kfd must exist</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># watch the GPU in another shell</span>
</span><span class="code-line">amd-smi monitor <span class="token parameter variable">--gpu</span> <span class="token number">0</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># run with &quot;offload as many layers as possible&quot;</span>
</span><span class="code-line">./build/bin/llama-cli   <span class="token parameter variable">-m</span> ~/AI/models/Qwen3-14B-Q4_K_M.gguf   <span class="token parameter variable">-ngl</span> <span class="token number">999</span> <span class="token parameter variable">-t</span> <span class="token number">4</span> <span class="token parameter variable">-c</span> <span class="token number">4096</span> <span class="token parameter variable">-b</span> <span class="token number">512</span> 
</span></code></pre></div>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/roc-eval.webp" alt="rocm eval"/></div>
<h3 id="token-statistics"><a href="#token-statistics" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Token statistics</h3>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/rocm-stats.webp" alt="rocm stats"/></div>
<hr/>
<h2 id="building--running-with-vulkan-no-rocm-needed"><a href="#building--running-with-vulkan-no-rocm-needed" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Building &amp; Running with <strong>Vulkan</strong> (No ROCm Needed)</h2>
<p>Vulkan is a handy fallback that skips the ROCm/KFD/Atomics fuss. It’s usually <strong>slower</strong> than ROCm on AMD, but it works well and only needs access to <code>/dev/dri/renderD*</code>.</p>
<h3 id="install-vulkan-runtime--dev-bits"><a href="#install-vulkan-runtime--dev-bits" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Install Vulkan runtime + dev bits</h3>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token function">sudo</span> <span class="token function">apt</span> update
</span><span class="code-line"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> <span class="token parameter variable">-y</span>   mesa-vulkan-drivers libvulkan1 libvulkan-dev vulkan-tools   glslc libshaderc-dev spirv-tools glslang-tools   build-essential cmake ninja-build pkg-config
</span><span class="code-line">
</span><span class="code-line"><span class="token comment"># check the GPU driver is visible to Vulkan</span>
</span><span class="code-line">vulkaninfo <span class="token operator">|</span> <span class="token function">egrep</span> <span class="token parameter variable">-i</span> <span class="token string">&#x27;GPU|driverName|apiVersion&#x27;</span> <span class="token operator">|</span> <span class="token function">head</span>
</span></code></pre></div>
<h3 id="build-llamacpp-with-vulkan"><a href="#build-llamacpp-with-vulkan" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Build llama.cpp with Vulkan</h3>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token builtin class-name">cd</span> ~/llama.cpp
</span><span class="code-line"><span class="token function">rm</span> <span class="token parameter variable">-rf</span> build
</span><span class="code-line">cmake <span class="token parameter variable">-S</span> <span class="token builtin class-name">.</span> <span class="token parameter variable">-B</span> build <span class="token parameter variable">-G</span> Ninja   <span class="token parameter variable">-DGGML_VULKAN</span><span class="token operator">=</span>ON   <span class="token parameter variable">-DCMAKE_BUILD_TYPE</span><span class="token operator">=</span>Release
</span><span class="code-line">cmake <span class="token parameter variable">--build</span> build -j<span class="token string">&quot;<span class="token variable"><span class="token variable">$(</span>nproc<span class="token variable">)</span></span>&quot;</span>
</span></code></pre></div>
<p>On startup you should see:</p>
<div class="relative"><pre><code class="code-highlight"><span class="code-line">ggml_vulkan: Found 1 Vulkan devices: ...
</span></code></pre></div>
<h3 id="run-llama-cli-with-vulkan"><a href="#run-llama-cli-with-vulkan" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Run llama-cli with Vulkan</h3>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token builtin class-name">export</span> <span class="token assign-left variable">GGML_VK_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span>  <span class="token comment"># optional if multiple GPUs</span>
</span><span class="code-line">
</span><span class="code-line">./build/bin/llama-cli   <span class="token parameter variable">-m</span> ~/AI/models/Qwen3-14B-Q4_K_M.gguf   <span class="token parameter variable">-ngl</span> <span class="token number">999</span> <span class="token parameter variable">-t</span> <span class="token number">4</span> <span class="token parameter variable">-c</span> <span class="token number">4096</span> <span class="token parameter variable">-b</span> <span class="token number">512</span> 
</span></code></pre></div>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/vulkun-eval.webp" alt="vulkan eval"/></div>
<h3 id="token-statistics-1"><a href="#token-statistics-1" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Token statistics</h3>
<div class="image-flex"><img src="/static/images/2025/gpu-experiment/vulkan-stats.webp" alt="PCIE 4X to Oculink SFF-8612"/></div><div class="mt-12 hidden lg:block"><div class="flex items-center my-8"><div class="flex-1 border-t border-gray-300 dark:border-gray-600"></div></div><p class="text-gray-700 dark:text-gray-300 font-medium mb-4">You might also enjoy these related guides and reviews:</p><div class="space-y-3"><a href="https://smarthomecircle.com/raspberry-pi-cm5-small-io-board-hands-on" class="group flex items-center space-x-3 py-1 px-0 transition-all duration-200"><div class="flex-shrink-0"><svg class="w-4 h-4 text-primary-600 dark:text-primary-400 transition-colors" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg></div><div class="flex-1 min-w-0"><span class="text-primary-600 dark:text-primary-400 hover:text-primary-700 dark:hover:text-primary-300 transition-colors font-medium underline hover:no-underline cursor-pointer">A palm-size IO board for Raspberry Pi CM5</span></div></a><a href="https://smarthomecircle.com/radxa-cubie-a5e-review-benchmarks-vs-raspberry-pi" class="group flex items-center space-x-3 py-1 px-0 transition-all duration-200"><div class="flex-shrink-0"><svg class="w-4 h-4 text-primary-600 dark:text-primary-400 transition-colors" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg></div><div class="flex-1 min-w-0"><span class="text-primary-600 dark:text-primary-400 hover:text-primary-700 dark:hover:text-primary-300 transition-colors font-medium underline hover:no-underline cursor-pointer">Radxa Cubie A5E Hands-On: The Budget NVMe SBC</span></div></a><a href="https://smarthomecircle.com/I-built-a-diy-10-inch-server-rack" class="group flex items-center space-x-3 py-1 px-0 transition-all duration-200"><div class="flex-shrink-0"><svg class="w-4 h-4 text-primary-600 dark:text-primary-400 transition-colors" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg></div><div class="flex-1 min-w-0"><span class="text-primary-600 dark:text-primary-400 hover:text-primary-700 dark:hover:text-primary-300 transition-colors font-medium underline hover:no-underline cursor-pointer">I Built A DIY 10 Inch Server Rack</span></div></a></div></div><div class="not-prose mt-8 pt-6 border-t border-gray-200 dark:border-gray-700"><div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4 p-4 bg-gray-50 dark:bg-gray-800/30 rounded-lg"><h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 flex-shrink-0">Share this article:</h3><div class="flex flex-wrap gap-2"><button type="button" class="text-white bg-[#3b5998] hover:bg-[#3b5998]/90 font-medium rounded-md text-xs px-3 py-1.5 inline-flex items-center transition-colors" title="Share on Facebook"><svg class="w-3 h-3 mr-1.5" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="facebook-f" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current"><path d="M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z"></path></svg></svg>Share</button><button type="button" class="text-white bg-[#1da1f2] hover:bg-[#1da1f2]/90 font-medium rounded-md text-xs px-3 py-1.5 inline-flex items-center transition-colors" title="Share on Twitter"><svg class="w-3 h-3 mr-1.5" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current"><path d="M23.953 4.57a10 10 0 0 1-2.825.775 4.958 4.958 0 0 0 2.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 0 0-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 0 0-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 0 1-2.228-.616v.06a4.923 4.923 0 0 0 3.946 4.827 4.996 4.996 0 0 1-2.212.085 4.936 4.936 0 0 0 4.604 3.417 9.867 9.867 0 0 1-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 0 0 7.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0 0 24 4.59z"></path></svg></svg>Tweet</button><button type="button" class="text-white bg-[#0077B5] hover:bg-[#00A0DC]/90 font-medium rounded-md text-xs px-3 py-1.5 inline-flex items-center transition-colors" title="Share on LinkedIn"><svg class="w-3 h-3 mr-1.5" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></svg>Post</button><button type="button" class="text-white bg-gray-600 hover:bg-gray-700 font-medium rounded-md text-xs px-3 py-1.5 inline-flex items-center transition-colors" title="Share via Email"><svg class="w-3 h-3 mr-1.5" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="email" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="fill-current"><path d="M2.003 5.884 10 9.882l7.997-3.998A2 2 0 0 0 16 4H4a2 2 0 0 0-1.997 1.884z"></path><path d="m18 8.118-8 4-8-4V14a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.118z"></path></svg></svg>Email</button></div></div></div></div></div><div class="lg:col-span-4 mt-12 lg:mt-0"><div class="space-y-8"><div class="bg-white dark:bg-gray-800 rounded-2xl p-6 shadow-lg border border-gray-200 dark:border-gray-700"><h3 class="text-lg font-semibold text-gray-900 dark:text-gray-100 mb-4">Tags</h3><div class="flex flex-wrap gap-2"><a class="m-1 p-1 px-2 leading-4 h-6 rounded text-xs uppercase text-white font-bold bg-teal-500 hover:bg-teal-400 dark:hover:bg-teal-500 dark:bg-teal-600" href="/tags/gpu">GPU</a><a class="m-1 p-1 px-2 leading-4 h-6 rounded text-xs uppercase text-white font-bold bg-teal-500 hover:bg-teal-400 dark:hover:bg-teal-500 dark:bg-teal-600" href="/tags/latte-panda">latte panda</a><a class="m-1 p-1 px-2 leading-4 h-6 rounded text-xs uppercase text-white font-bold bg-teal-500 hover:bg-teal-400 dark:hover:bg-teal-500 dark:bg-teal-600" href="/tags/sbc">SBC</a><a class="m-1 p-1 px-2 leading-4 h-6 rounded text-xs uppercase text-white font-bold bg-teal-500 hover:bg-teal-400 dark:hover:bg-teal-500 dark:bg-teal-600" href="/tags/ai">AI</a><a class="m-1 p-1 px-2 leading-4 h-6 rounded text-xs uppercase text-white font-bold bg-teal-500 hover:bg-teal-400 dark:hover:bg-teal-500 dark:bg-teal-600" href="/tags/vulkan">Vulkan</a><a class="m-1 p-1 px-2 leading-4 h-6 rounded text-xs uppercase text-white font-bold bg-teal-500 hover:bg-teal-400 dark:hover:bg-teal-500 dark:bg-teal-600" href="/tags/ollama">ollama</a><a class="m-1 p-1 px-2 leading-4 h-6 rounded text-xs uppercase text-white font-bold bg-teal-500 hover:bg-teal-400 dark:hover:bg-teal-500 dark:bg-teal-600" href="/tags/llama-cpp">llama cpp</a></div></div><div class="bg-white dark:bg-gray-800 rounded-2xl p-6 shadow-lg border border-gray-200 dark:border-gray-700"><h3 class="text-lg font-semibold text-gray-900 dark:text-gray-100 mb-6">Suggested Articles</h3><div class="space-y-6"><div><a href="https://smarthomecircle.com/raspberry-pi-cm5-small-io-board-hands-on" class="block group"><div class="flex items-start space-x-3"><svg class="w-5 h-5 text-primary-500 mt-0.5 flex-shrink-0 group-hover:text-primary-600 dark:group-hover:text-primary-400 transition-colors" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg><div class="flex-1 min-w-0"><div class="text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 font-medium group-hover:underline transition-colors">A palm-size IO board for Raspberry Pi CM5</div></div><svg class="w-4 h-4 text-gray-400 group-hover:text-primary-500 transform group-hover:translate-x-1 transition-all duration-200 flex-shrink-0" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg></div></a></div><div><a href="https://smarthomecircle.com/radxa-cubie-a5e-review-benchmarks-vs-raspberry-pi" class="block group"><div class="flex items-start space-x-3"><svg class="w-5 h-5 text-primary-500 mt-0.5 flex-shrink-0 group-hover:text-primary-600 dark:group-hover:text-primary-400 transition-colors" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg><div class="flex-1 min-w-0"><div class="text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 font-medium group-hover:underline transition-colors">Radxa Cubie A5E Hands-On: The Budget NVMe SBC</div></div><svg class="w-4 h-4 text-gray-400 group-hover:text-primary-500 transform group-hover:translate-x-1 transition-all duration-200 flex-shrink-0" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg></div></a></div><div><a href="https://smarthomecircle.com/I-built-a-diy-10-inch-server-rack" class="block group"><div class="flex items-start space-x-3"><svg class="w-5 h-5 text-primary-500 mt-0.5 flex-shrink-0 group-hover:text-primary-600 dark:group-hover:text-primary-400 transition-colors" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg><div class="flex-1 min-w-0"><div class="text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 font-medium group-hover:underline transition-colors">I Built A DIY 10 Inch Server Rack</div></div><svg class="w-4 h-4 text-gray-400 group-hover:text-primary-500 transform group-hover:translate-x-1 transition-all duration-200 flex-shrink-0" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg></div></a></div></div></div><div class="bg-gradient-to-br from-primary-50 to-primary-100 dark:from-primary-900/20 dark:to-primary-800/20 rounded-2xl p-6 border border-primary-200 dark:border-primary-800"><a class="flex items-center text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 font-semibold transition-colors group" href="/"><svg class="w-5 h-5 mr-2 transform group-hover:-translate-x-1 transition-transform" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"></path></svg>Back to Articles</a></div></div></div></div></div></article></div></main><footer><div class="flex flex-col items-center mt-16"><div class="flex mb-3 space-x-4"><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="mailto:contactsmarthomecircle@gmail.com"><span class="sr-only">mail</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M2.003 5.884 10 9.882l7.997-3.998A2 2 0 0 0 16 4H4a2 2 0 0 0-1.997 1.884z"></path><path d="m18 8.118-8 4-8-4V14a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.118z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/@SmartHomeCircle"><span class="sr-only">youtube</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M23.499 6.203a3.008 3.008 0 0 0-2.089-2.089c-1.87-.501-9.4-.501-9.4-.501s-7.509-.01-9.399.501a3.008 3.008 0 0 0-2.088 2.09A31.258 31.26 0 0 0 0 12.01a31.258 31.26 0 0 0 .523 5.785 3.008 3.008 0 0 0 2.088 2.089c1.869.502 9.4.502 9.4.502s7.508 0 9.399-.502a3.008 3.008 0 0 0 2.089-2.09 31.258 31.26 0 0 0 .5-5.784 31.258 31.26 0 0 0-.5-5.808zm-13.891 9.4V8.407l6.266 3.604z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://twitter.com/smarthomecircle"><span class="sr-only">twitter</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M23.953 4.57a10 10 0 0 1-2.825.775 4.958 4.958 0 0 0 2.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 0 0-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 0 0-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 0 1-2.228-.616v.06a4.923 4.923 0 0 0 3.946 4.827 4.996 4.996 0 0 1-2.212.085 4.936 4.936 0 0 0 4.604 3.417 9.867 9.867 0 0 1-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 0 0 7.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0 0 24 4.59z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://bsky.app/profile/smarthomecircle.com"><span class="sr-only">blueSky</span><svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M12 10.8c-1.087-2.114-4.046-6.053-6.798-7.995C2.566.944 1.561 1.266.902 1.565.139 1.908 0 3.08 0 3.768c0 .69.378 5.65.624 6.479.815 2.736 3.713 3.66 6.383 3.364.136-.02.275-.039.415-.056-.138.022-.276.04-.415.056-3.912.58-7.387 2.005-2.83 7.078 5.013 5.19 6.87-1.113 7.823-4.308.953 3.195 2.05 9.271 7.733 4.308 4.267-4.308 1.172-6.498-2.74-7.078a8.741 8.741 0 0 1-.415-.056c.14.017.279.036.415.056 2.67.297 5.568-.628 6.383-3.364.246-.828.624-5.79.624-6.478 0-.69-.139-1.861-.902-2.206-.659-.298-1.664-.62-4.3 1.24C16.046 4.748 13.087 8.687 12 10.8Z"></path></svg></a></div><div class="flex mb-2 space-x-2 text-sm text-gray-500 dark:text-gray-400"><div>Amrut Prabhu</div><div> • </div><div>© 2025</div><div> • </div><a href="/">Smart Home Circle</a><div> • </div><a href="/privacy">Privacy Policy</a></div><br/></div></footer></div></div><div class="max-w-3xl px-4 mx-auto sm:px-6 xl:max-w-6xl xl:px-0"><div id="cookie-notice" class="consent_consentname__W_12w"><br/><br/><p>By clicking “I Accept”, you agree to the storing of cookies on your device to enhance site navigation and analyze site usage</p><br/><br/><div><a id="cookie-notice-accept" class="consent_greenButton__rKcAp">I Accept</a><a href="/privacy">Privacy Policy</a></div><br/><br/><br/></div></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"post":{"mdxSource":"var Component=(()=\u003e{var m=Object.create;var c=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var k=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var t=n=\u003ec(n,\"__esModule\",{value:!0});var g=(n,s)=\u003e()=\u003e(s||n((s={exports:{}}).exports,s),s.exports),b=(n,s)=\u003e{t(n);for(var l in s)c(n,l,{get:s[l],enumerable:!0})},f=(n,s,l)=\u003e{if(s\u0026\u0026typeof s==\"object\"||typeof s==\"function\")for(let a of u(s))!N.call(n,a)\u0026\u0026a!==\"default\"\u0026\u0026c(n,a,{get:()=\u003es[a],enumerable:!(l=p(s,a))||l.enumerable});return n},v=n=\u003ef(t(c(n!=null?m(k(n)):{},\"default\",n\u0026\u0026n.__esModule\u0026\u0026\"default\"in n?{get:()=\u003en.default,enumerable:!0}:{value:n,enumerable:!0})),n);var d=g((A,o)=\u003e{o.exports=_jsx_runtime});var M={};b(M,{default:()=\u003eI,frontmatter:()=\u003ex});var e=v(d()),x={title:\"Running an AMD Instinct MI50 on a LattePanda Mu Lite (OCuLink eGPU) for Local LLMs\",author:\"Amrut Prabhu\",categories:\"\",tags:[\"GPU\",\"latte panda\",\"SBC\",\"AI\",\"Vulkan\",\"ollama\",\"llama cpp\"],\"photo-credits\":null,\"applaud-link\":\"2021/spring-boot-stream-kafka.json\",date:\"2025-11-13\",draft:!1,autoAds:!0,summary:\"Step-by-step AMD Instinct MI50 eGPU on LattePanda Mu Lite carrier board: Ubuntu 24.04 HWE, ROCm, Vulkan, Ollama \u0026 llama.cpp on GPU, PCIe/OCuLink\",imageUrl:\"/static/images/2025/gpu-experiment/cover.webp\",actualUrl:\"auto-generated\",customUrl:\"auto-generated\",youtubeLink:\"https://www.youtube.com/embed/iXYsRK_gqTA\",suggestedArticles:[{title:\"A palm-size IO board for Raspberry Pi CM5\",url:\"https://smarthomecircle.com/raspberry-pi-cm5-small-io-board-hands-on\"},{title:\"Radxa Cubie A5E Hands-On: The Budget NVMe SBC\",url:\"https://smarthomecircle.com/radxa-cubie-a5e-review-benchmarks-vs-raspberry-pi\"},{title:\"I Built A DIY 10 Inch Server Rack\",url:\"https://smarthomecircle.com/I-built-a-diy-10-inch-server-rack\"}]};function w(n={}){let{wrapper:s}=n.components||{};return s?(0,e.jsx)(s,Object.assign({},n,{children:(0,e.jsx)(l,{})})):l();function l(){let a=Object.assign({p:\"p\",strong:\"strong\",hr:\"hr\",h2:\"h2\",a:\"a\",span:\"span\",ul:\"ul\",li:\"li\",code:\"code\",em:\"em\",pre:\"pre\",h3:\"h3\",blockquote:\"blockquote\"},n.components),{TOCInline:r,AffiliateLinks:i}=a;return i||h(\"AffiliateLinks\",!0),r||h(\"TOCInline\",!0),(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(r,{toc:n.toc,asDisclosure:!0}),`\n`,(0,e.jsxs)(a.p,{children:[\"I\\u2019ve been tinkering with a \",(0,e.jsx)(a.strong,{children:\"LattePanda Mu Lite\"}),\" and an \",(0,e.jsx)(a.strong,{children:\"AMD Instinct MI50 (16 GB HBM2)\"}),\" in an \",(0,e.jsx)(a.strong,{children:\"eGPU\"}),\" setup over \",(0,e.jsx)(a.strong,{children:\"OCuLink\"}),\". My end-goals: run \",(0,e.jsx)(a.strong,{children:\"Ollama\"}),\" and \",(0,e.jsx)(a.strong,{children:\"llama.cpp\"}),\" with GPU acceleration on \",(0,e.jsx)(a.strong,{children:\"Ubuntu 24.04 LTS\"}),\".\"]}),`\n`,(0,e.jsx)(a.p,{children:\"This is my living log: everything I did, what worked, and the exact commands I used\\u2014warts and all. I\\u2019m writing it as a first\\u2011person guide so you can follow (or avoid) my footsteps.\"}),`\n`,(0,e.jsx)(a.hr,{}),`\n`,(0,e.jsxs)(a.h2,{id:\"hardware--topology-i-used\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#hardware--topology-i-used\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Hardware \u0026 Topology I Used\"]}),`\n`,(0,e.jsxs)(a.ul,{children:[`\n`,(0,e.jsxs)(a.li,{children:[(0,e.jsx)(a.strong,{children:\"Host:\"}),\" \",(0,e.jsx)(a.strong,{children:\"LattePanda Mu Lite\"}),\" carrier board, Ubuntu \",(0,e.jsx)(a.strong,{children:\"24.04.1 LTS\"}),\" (kernel was \",(0,e.jsx)(a.code,{children:\"6.14.0-33-generic\"}),\" in my case)\"]}),`\n`]}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/latte-panda-mu.webp\",alt:\"vulkan eval\"})}),`\n`,(0,e.jsx)(i,{title:\"Latte Panda Mu Lite Carrier Board\",links:[{store:\"Amazon DE\",url:\"https://amzn.to/4qQevai\"},{store:\"Amazon US\",url:\"https://amzn.to/3WLJS88\"}]}),`\n`,(0,e.jsxs)(a.ul,{children:[`\n`,(0,e.jsxs)(a.li,{children:[(0,e.jsx)(a.strong,{children:\"GPU:\"}),\" AMD \",(0,e.jsx)(a.strong,{children:\"Instinct MI50\"}),\" (gfx906, 16 GB HBM2, passive)\"]}),`\n`]}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/amd-instinct-mi50.webp\",alt:\"Amd instinct mi50\"})}),`\n`,(0,e.jsxs)(a.ul,{children:[`\n`,(0,e.jsx)(a.li,{children:(0,e.jsx)(a.strong,{children:\"eGPU + Oculink cable:\"})}),`\n`]}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/egpu.jpg\",alt:\"vulkan eval\"})}),`\n`,(0,e.jsx)(i,{title:\"eGPU Mount with Oculink Cable\",links:[{store:\"AliExpress\",url:\"https://s.click.aliexpress.com/e/_c3Gutyd1\"},{store:\"Amazon US\",url:\"https://amzn.to/4nEnY1v\"},{store:\"Amazon DE\",url:\"https://amzn.to/43mrXbU\"}]}),`\n`,(0,e.jsxs)(a.p,{children:[(0,e.jsx)(a.strong,{children:\"Connection :\"}),\" Mu Lite \",(0,e.jsx)(a.strong,{children:\"PCIe x4\"}),\" slot \\u2192 \",(0,e.jsx)(a.strong,{children:\"OCuLink\"}),\" host adapter \\u2192 OCuLink cable \\u2192 x16 eGPU riser/backplane \\u2192 \",(0,e.jsx)(a.strong,{children:\"MI50\"})]}),`\n`,(0,e.jsxs)(a.ul,{children:[`\n`,(0,e.jsx)(a.li,{children:(0,e.jsx)(a.strong,{children:\"PCIE 4X to Oculink SFF-8612\"})}),`\n`]}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/pcie-adapter.webp\",alt:\"PCIE 4X to Oculink SFF-8612\"})}),`\n`,(0,e.jsx)(i,{title:\"PCIE 4X to Oculink SFF-8612\",links:[{store:\"AliExpress\",url:\"https://s.click.aliexpress.com/e/_c3X4MKnV\"},{store:\"Amazon US\",url:\"https://amzn.to/3JNQL61\"},{store:\"Amazon DE\",url:\"https://amzn.to/49kKVDH\"}]}),`\n`,(0,e.jsxs)(a.ul,{children:[`\n`,(0,e.jsxs)(a.li,{children:[(0,e.jsx)(a.strong,{children:\"Power:\"}),\" 12 V for the carrier (required for the on-board PCIe slot), ATX PSU for the MI50 (2\\xD7 8\\u2011pin), \",(0,e.jsx)(a.em,{children:\"lots\"}),\" of airflow through the passive heatsink\"]}),`\n`]}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/full-setup.webp\",alt:\"full setup\"})}),`\n`,(0,e.jsx)(a.hr,{}),`\n`,(0,e.jsxs)(a.h2,{id:\"os-install--first-detection\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#os-install--first-detection\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"OS Install \u0026 First Detection\"]}),`\n`,(0,e.jsxs)(a.p,{children:[\"I did a \",(0,e.jsx)(a.strong,{children:\"fresh Ubuntu 24.04.1\"}),\" install to NVMe. After connecting the eGPU chain and powering the GPU first, I booted the Mu and SSH\\u2019d in.\"]}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/ubuntu.webp\",alt:\"ubuntu\"})}),`\n`,(0,e.jsx)(a.p,{children:\"Check that the GPU is seen on the bus:\"}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"lspci \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"|\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"egrep\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-i\"}),\" \",(0,e.jsx)(a.span,{className:\"token string\",children:\"'amd|ati|vega|instinct'\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" lspci \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"|\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"egrep\"}),\" \",(0,e.jsx)(a.span,{className:\"token string\",children:\"'LnkCap|LnkSta'\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"# I expect: Speed 8GT/s, Width x4  (PCIe 3.0 x4 over OCuLink)\"}),`\n`]})]})}),`\n`,(0,e.jsx)(a.hr,{}),`\n`,(0,e.jsxs)(a.h2,{id:\"install-the-ubuntu-hwe-kernel-recommended-before-amd-drivers\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#install-the-ubuntu-hwe-kernel-recommended-before-amd-drivers\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Install the Ubuntu HWE kernel (recommended, before AMD drivers)\"]}),`\n`,(0,e.jsxs)(a.p,{children:[\"Before installing the AMD GPU drivers/ROCm stack, I install the Ubuntu 24.04 \",(0,e.jsx)(a.strong,{children:\"HWE kernel\"}),\". This keeps me on the supported kernel stream and ensures the extra kernel modules (like \",(0,e.jsx)(a.strong,{children:\"KFD\"}),\") are available for my running kernel.\"]}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"apt\"}),` update\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"apt\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"install\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-y\"}),` linux-generic-hwe-24.04\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"reboot\"}),`\n`]})]})}),`\n`,(0,e.jsxs)(a.p,{children:[\"If \",(0,e.jsx)(a.code,{children:\"/dev/kfd\"}),\" or other modules are missing on the new kernel, I install the \",(0,e.jsx)(a.strong,{children:\"modules-extra\"}),\" package that matches the \",(0,e.jsx)(a.em,{children:\"running\"}),\" kernel:\"]}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsx)(a.code,{className:\"language-bash code-highlight\",children:(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"apt\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"install\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-y\"}),\" \",(0,e.jsxs)(a.span,{className:\"token string\",children:['\"linux-modules-extra-',(0,e.jsxs)(a.span,{className:\"token variable\",children:[(0,e.jsx)(a.span,{className:\"token variable\",children:\"$(\"}),(0,e.jsx)(a.span,{className:\"token function\",children:\"uname\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-r\"}),(0,e.jsx)(a.span,{className:\"token variable\",children:\")\"})]}),'\"']}),`\n`]})})}),`\n`,(0,e.jsxs)(a.h2,{id:\"amd-driver--rocm-what-actually-worked\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#amd-driver--rocm-what-actually-worked\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"AMD Driver + ROCm: What Actually Worked\"]}),`\n`,(0,e.jsxs)(a.p,{children:[\"My goal was to get \",(0,e.jsx)(a.strong,{children:\"ROCm\"}),\" working so apps can use the GPU (\",(0,e.jsx)(a.strong,{children:\"/dev/kfd\"}),\" must exist). Here\\u2019s the exact path that worked for me.\"]}),`\n`,(0,e.jsxs)(a.h3,{id:\"install-the-amd-driver-installer-702-then-rocm\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#install-the-amd-driver-installer-702-then-rocm\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Install the AMD driver installer 7.0.2, then ROCm\"]}),`\n`,(0,e.jsxs)(a.p,{children:[\"I am installed the AMD installer from the AMD \",(0,e.jsx)(a.a,{href:\"https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/quick-start.html#rocm-install-quick\",children:\"site\"}),\".\"]}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"wget\"}),` https://repo.radeon.com/amdgpu-install/7.0.2/ubuntu/noble/amdgpu-install_7.0.2.70002-1_all.deb\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"apt\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"install\"}),` ./amdgpu-install_7.0.2.70002-1_all.deb\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"# install ROCm user-space + graphics, but NO DKMS\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" amdgpu-install \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-y\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"--usecase\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),`rocm\n`]})]})}),`\n`,(0,e.jsxs)(a.p,{children:[\"I then copied the required files as mentioned in this \",(0,e.jsx)(a.a,{href:\"\",children:\"reddit post\"})]}),`\n`,(0,e.jsx)(a.pre,{children:(0,e.jsxs)(a.code,{className:\"code-highlight\",children:[(0,e.jsx)(a.span,{className:\"code-line\",children:`1. Download the 6.4 rocblas from here: https://archlinux.org/packages/extra/x86_64/rocblas/\n`}),(0,e.jsx)(a.span,{className:\"code-line\",children:`2. Extract it \n`}),(0,e.jsx)(a.span,{className:\"code-line\",children:`3. Copy all tensor files that contain gfx906 in rocblas-6.4.3-3-x86_64.pkg/opt/rocm/lib/rocblas/library to /opt/rocm/lib/rocblas/library\n`}),(0,e.jsx)(a.span,{className:\"code-line\",children:`4. sudo reboot\n`})]})}),`\n`,(0,e.jsx)(a.p,{children:(0,e.jsx)(a.em,{children:(0,e.jsx)(a.a,{href:\"https://www.reddit.com/r/linux4noobs/comments/1ly8rq6/comment/nb9uiye/?utm_source=share\u0026utm_medium=web3x\u0026utm_name=web3xcss\u0026utm_term=1\u0026utm_content=share_button\",children:\"source\"})})}),`\n`,(0,e.jsxs)(a.h2,{id:\"ollama-with-amd-rocm\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#ollama-with-amd-rocm\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Ollama with AMD ROCm\"]}),`\n`,(0,e.jsx)(a.p,{children:\"I installed Ollama using the command from the ollama site\"}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"curl\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-fsSL\"}),\" https://ollama.com/install.sh \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"|\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"sh\"}),`\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"#then started the ollama server\"}),`\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`ollama serve\n`})]})}),`\n`,(0,e.jsxs)(a.blockquote,{children:[`\n`,(0,e.jsxs)(a.p,{children:[(0,e.jsx)(a.strong,{children:\"Update:\"}),\"  Ollama dropped support for the \",(0,e.jsx)(a.code,{children:\"gfx906\"}),\" in the \",(0,e.jsx)(a.code,{children:\"0.12.5\"}),\" \",(0,e.jsx)(a.a,{href:\"http://github.com/ollama/ollama/releases/tag/v0.12.5\",children:\"release\"}),\". However there is an \",(0,e.jsx)(a.a,{href:\"https://github.com/ollama/ollama/issues/12600\",children:\"issue\"}),\" created to add back the support for \",(0,e.jsx)(a.code,{children:\"gfx906\"})]}),`\n`]}),`\n`,(0,e.jsxs)(a.p,{children:[(0,e.jsx)(a.strong,{children:\"If I run it as a systemd service\"}),\", I make sure the service user has device access:\"]}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"# give the 'ollama' user access (if it exists)\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"getent \",(0,e.jsx)(a.span,{className:\"token function\",children:\"passwd\"}),\" ollama \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"\u003e\"}),\"/dev/null \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"\u0026\u0026\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"usermod\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-a\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-G\"}),` render,video ollama\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"# ensure the service gets those groups\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"mkdir\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-p\"}),` /etc/systemd/system/ollama.service.d\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token builtin class-name\",children:\"printf\"}),\" \",(0,e.jsx)(a.span,{className:\"token string\",children:`\"[Service]\n`})]}),(0,e.jsx)(a.span,{className:\"code-line\",children:(0,e.jsx)(a.span,{className:\"token string\",children:`SupplementaryGroups=render video\n`})}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token string\",children:'\"'}),\" \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"|\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"tee\"}),` /etc/systemd/system/ollama.service.d/rocm.conf\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),` systemctl daemon-reload\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),` systemctl restart ollama\n`]})]})}),`\n`,(0,e.jsxs)(a.p,{children:[(0,e.jsx)(a.strong,{children:\"Sanity test\"}),\" (watch the GPU in another shell):\"]}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"amd-smi monitor \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"--gpu\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"0\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"ollama run llama3.1:8b \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"--verbose\"}),`\n`]})]})}),`\n`,(0,e.jsx)(a.hr,{}),`\n`,(0,e.jsxs)(a.h2,{id:\"building-llamacpp-for-amd-rocm-hip\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#building-llamacpp-for-amd-rocm-hip\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Building llama.cpp for AMD ROCm (HIP)\"]}),`\n`,(0,e.jsx)(a.p,{children:\"The supported flagset has changed over time. What worked reliably for me:\"}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"apt\"}),` update\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"apt\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"install\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-y\"}),` build-essential cmake ninja-build pkg-config libcurl4-openssl-dev\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"git\"}),` clone https://github.com/ggml-org/llama.cpp.git\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"# from the repo root:\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token builtin class-name\",children:\"cd\"}),` ~/llama.cpp\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"rm\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-rf\"}),` build\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"# Configure for ROCm/HIP; target MI50's gfx906\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token assign-left variable\",children:\"HIPCXX\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),(0,e.jsxs)(a.span,{className:\"token string\",children:['\"',(0,e.jsxs)(a.span,{className:\"token variable\",children:[(0,e.jsx)(a.span,{className:\"token variable\",children:\"$(\"}),\"hipconfig \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-l\"}),(0,e.jsx)(a.span,{className:\"token variable\",children:\")\"})]}),'/clang\"']}),\" \",(0,e.jsx)(a.span,{className:\"token assign-left variable\",children:\"HIP_PATH\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),(0,e.jsxs)(a.span,{className:\"token string\",children:['\"',(0,e.jsxs)(a.span,{className:\"token variable\",children:[(0,e.jsx)(a.span,{className:\"token variable\",children:\"$(\"}),\"hipconfig \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-R\"}),(0,e.jsx)(a.span,{className:\"token variable\",children:\")\"})]}),'\"']}),\" cmake \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-S\"}),\" \",(0,e.jsx)(a.span,{className:\"token builtin class-name\",children:\".\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-B\"}),\" build \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-G\"}),\" Ninja   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-DGGML_HIP\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),\"ON   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-DAMDGPU_TARGETS\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),\"gfx906   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-DCMAKE_BUILD_TYPE\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),\"Release   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-DLLAMA_CURL\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),\"ON   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-DCMAKE_PREFIX_PATH\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),`/opt/rocm\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"cmake \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"--build\"}),\" build -j\",(0,e.jsxs)(a.span,{className:\"token string\",children:['\"',(0,e.jsxs)(a.span,{className:\"token variable\",children:[(0,e.jsx)(a.span,{className:\"token variable\",children:\"$(\"}),\"nproc\",(0,e.jsx)(a.span,{className:\"token variable\",children:\")\"})]}),'\"']}),`\n`]})]})}),`\n`,(0,e.jsxs)(a.p,{children:[(0,e.jsx)(a.strong,{children:\"How I knew it worked:\"}),\" on startup, \",(0,e.jsx)(a.code,{children:\"llama-cli\"}),\" printed something like:\"]}),`\n`,(0,e.jsx)(a.pre,{children:(0,e.jsxs)(a.code,{className:\"code-highlight\",children:[(0,e.jsx)(a.span,{className:\"code-line\",children:`ggml_cuda_init: found 1 ROCm devices:\n`}),(0,e.jsx)(a.span,{className:\"code-line\",children:`  Device 0: AMD Instinct MI50/MI60, gfx906:sramecc+:xnack- ...\n`})]})}),`\n`,(0,e.jsx)(a.hr,{}),`\n`,(0,e.jsxs)(a.h2,{id:\"running-a-model-with-llamacpp-on-rocm\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#running-a-model-with-llamacpp-on-rocm\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Running a Model with llama.cpp on ROCm\"]}),`\n`,(0,e.jsxs)(a.p,{children:[\"I used a \",(0,e.jsx)(a.strong,{children:\"Qwen3\\u201114B GGUF\"}),\" from a GGUF repository. I grabbed the new HF CLI and downloaded a \",(0,e.jsx)(a.strong,{children:\"Q4_K_M\"}),\" quant (fits in 16 GB):\"]}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"python3 \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-m\"}),\" pip \",(0,e.jsx)(a.span,{className:\"token function\",children:\"install\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-U\"}),\" \",(0,e.jsx)(a.span,{className:\"token string\",children:'\"huggingface_hub[cli]\"'}),`\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"hf download Qwen/Qwen3-14B-GGUF   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"--include\"}),\" \",(0,e.jsx)(a.span,{className:\"token string\",children:'\"Qwen3-14B-Q4_K_M.gguf\"'}),`   --local-dir ~/AI/models\n`]})]})}),`\n`,(0,e.jsx)(a.p,{children:\"Run it:\"}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"# make sure compute devices exist (per boot)\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" modprobe amdgpu \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"\u0026\u0026\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),` modprobe amdkfd\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"ls\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-l\"}),\" /dev/kfd /dev/dri/renderD*    \",(0,e.jsx)(a.span,{className:\"token comment\",children:\"# /dev/kfd must exist\"}),`\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"# watch the GPU in another shell\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"amd-smi monitor \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"--gpu\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"0\"}),`\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:'# run with \"offload as many layers as possible\"'}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"./build/bin/llama-cli   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-m\"}),\" ~/AI/models/Qwen3-14B-Q4_K_M.gguf   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-ngl\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"999\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-t\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"4\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-c\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"4096\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-b\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"512\"}),` \n`]})]})}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/roc-eval.webp\",alt:\"rocm eval\"})}),`\n`,(0,e.jsxs)(a.h3,{id:\"token-statistics\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#token-statistics\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Token statistics\"]}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/rocm-stats.webp\",alt:\"rocm stats\"})}),`\n`,(0,e.jsx)(a.hr,{}),`\n`,(0,e.jsxs)(a.h2,{id:\"building--running-with-vulkan-no-rocm-needed\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#building--running-with-vulkan-no-rocm-needed\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Building \u0026 Running with \",(0,e.jsx)(a.strong,{children:\"Vulkan\"}),\" (No ROCm Needed)\"]}),`\n`,(0,e.jsxs)(a.p,{children:[\"Vulkan is a handy fallback that skips the ROCm/KFD/Atomics fuss. It\\u2019s usually \",(0,e.jsx)(a.strong,{children:\"slower\"}),\" than ROCm on AMD, but it works well and only needs access to \",(0,e.jsx)(a.code,{children:\"/dev/dri/renderD*\"}),\".\"]}),`\n`,(0,e.jsxs)(a.h3,{id:\"install-vulkan-runtime--dev-bits\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#install-vulkan-runtime--dev-bits\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Install Vulkan runtime + dev bits\"]}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"apt\"}),` update\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"sudo\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"apt\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"install\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-y\"}),`   mesa-vulkan-drivers libvulkan1 libvulkan-dev vulkan-tools   glslc libshaderc-dev spirv-tools glslang-tools   build-essential cmake ninja-build pkg-config\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token comment\",children:\"# check the GPU driver is visible to Vulkan\"}),`\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"vulkaninfo \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"|\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"egrep\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-i\"}),\" \",(0,e.jsx)(a.span,{className:\"token string\",children:\"'GPU|driverName|apiVersion'\"}),\" \",(0,e.jsx)(a.span,{className:\"token operator\",children:\"|\"}),\" \",(0,e.jsx)(a.span,{className:\"token function\",children:\"head\"}),`\n`]})]})}),`\n`,(0,e.jsxs)(a.h3,{id:\"build-llamacpp-with-vulkan\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#build-llamacpp-with-vulkan\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Build llama.cpp with Vulkan\"]}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token builtin class-name\",children:\"cd\"}),` ~/llama.cpp\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token function\",children:\"rm\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-rf\"}),` build\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"cmake \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-S\"}),\" \",(0,e.jsx)(a.span,{className:\"token builtin class-name\",children:\".\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-B\"}),\" build \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-G\"}),\" Ninja   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-DGGML_VULKAN\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),\"ON   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-DCMAKE_BUILD_TYPE\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),`Release\n`]}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"cmake \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"--build\"}),\" build -j\",(0,e.jsxs)(a.span,{className:\"token string\",children:['\"',(0,e.jsxs)(a.span,{className:\"token variable\",children:[(0,e.jsx)(a.span,{className:\"token variable\",children:\"$(\"}),\"nproc\",(0,e.jsx)(a.span,{className:\"token variable\",children:\")\"})]}),'\"']}),`\n`]})]})}),`\n`,(0,e.jsx)(a.p,{children:\"On startup you should see:\"}),`\n`,(0,e.jsx)(a.pre,{children:(0,e.jsx)(a.code,{className:\"code-highlight\",children:(0,e.jsx)(a.span,{className:\"code-line\",children:`ggml_vulkan: Found 1 Vulkan devices: ...\n`})})}),`\n`,(0,e.jsxs)(a.h3,{id:\"run-llama-cli-with-vulkan\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#run-llama-cli-with-vulkan\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Run llama-cli with Vulkan\"]}),`\n`,(0,e.jsx)(a.pre,{className:\"language-bash\",children:(0,e.jsxs)(a.code,{className:\"language-bash code-highlight\",children:[(0,e.jsxs)(a.span,{className:\"code-line\",children:[(0,e.jsx)(a.span,{className:\"token builtin class-name\",children:\"export\"}),\" \",(0,e.jsx)(a.span,{className:\"token assign-left variable\",children:\"GGML_VK_VISIBLE_DEVICES\"}),(0,e.jsx)(a.span,{className:\"token operator\",children:\"=\"}),(0,e.jsx)(a.span,{className:\"token number\",children:\"0\"}),\"  \",(0,e.jsx)(a.span,{className:\"token comment\",children:\"# optional if multiple GPUs\"}),`\n`]}),(0,e.jsx)(a.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(a.span,{className:\"code-line\",children:[\"./build/bin/llama-cli   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-m\"}),\" ~/AI/models/Qwen3-14B-Q4_K_M.gguf   \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-ngl\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"999\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-t\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"4\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-c\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"4096\"}),\" \",(0,e.jsx)(a.span,{className:\"token parameter variable\",children:\"-b\"}),\" \",(0,e.jsx)(a.span,{className:\"token number\",children:\"512\"}),` \n`]})]})}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/vulkun-eval.webp\",alt:\"vulkan eval\"})}),`\n`,(0,e.jsxs)(a.h3,{id:\"token-statistics-1\",children:[(0,e.jsx)(a.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#token-statistics-1\",children:(0,e.jsx)(a.span,{className:\"icon icon-link\"})}),\"Token statistics\"]}),`\n`,(0,e.jsx)(\"div\",{class:\"image-flex\",children:(0,e.jsx)(\"img\",{src:\"/static/images/2025/gpu-experiment/vulkan-stats.webp\",alt:\"PCIE 4X to Oculink SFF-8612\"})})]})}}var I=w;function h(n,s){throw new Error(\"Expected \"+(s?\"component\":\"object\")+\" `\"+n+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return M;})();\n;return Component;","toc":[{"value":"Hardware \u0026 Topology I Used","url":"#hardware--topology-i-used","depth":2},{"value":"OS Install \u0026 First Detection","url":"#os-install--first-detection","depth":2},{"value":"Install the Ubuntu HWE kernel (recommended, before AMD drivers)","url":"#install-the-ubuntu-hwe-kernel-recommended-before-amd-drivers","depth":2},{"value":"AMD Driver + ROCm: What Actually Worked","url":"#amd-driver--rocm-what-actually-worked","depth":2},{"value":"Install the AMD driver installer 7.0.2, then ROCm","url":"#install-the-amd-driver-installer-702-then-rocm","depth":3},{"value":"Ollama with AMD ROCm","url":"#ollama-with-amd-rocm","depth":2},{"value":"Building llama.cpp for AMD ROCm (HIP)","url":"#building-llamacpp-for-amd-rocm-hip","depth":2},{"value":"Running a Model with llama.cpp on ROCm","url":"#running-a-model-with-llamacpp-on-rocm","depth":2},{"value":"Token statistics","url":"#token-statistics","depth":3},{"value":"Building \u0026 Running with Vulkan (No ROCm Needed)","url":"#building--running-with-vulkan-no-rocm-needed","depth":2},{"value":"Install Vulkan runtime + dev bits","url":"#install-vulkan-runtime--dev-bits","depth":3},{"value":"Build llama.cpp with Vulkan","url":"#build-llamacpp-with-vulkan","depth":3},{"value":"Run llama-cli with Vulkan","url":"#run-llama-cli-with-vulkan","depth":3},{"value":"Token statistics","url":"#token-statistics","depth":3}],"frontMatter":{"readingTime":{"text":"5 min read","minutes":4.055,"time":243300,"words":811},"slug":"2025/run-gpu-on-latte-panda-mu-lite-carrier-board","fileName":"2025/run-gpu-on-latte-panda-mu-lite-carrier-board.md","title":"Running an AMD Instinct MI50 on a LattePanda Mu Lite (OCuLink eGPU) for Local LLMs","author":"Amrut Prabhu","categories":"","tags":["GPU","latte panda","SBC","AI","Vulkan","ollama","llama cpp"],"photo-credits":null,"applaud-link":"2021/spring-boot-stream-kafka.json","date":"2025-11-13T00:00:00.000Z","draft":false,"autoAds":true,"summary":"Step-by-step AMD Instinct MI50 eGPU on LattePanda Mu Lite carrier board: Ubuntu 24.04 HWE, ROCm, Vulkan, Ollama \u0026 llama.cpp on GPU, PCIe/OCuLink","imageUrl":"/static/images/2025/gpu-experiment/cover.webp","actualUrl":"2025/run-gpu-on-latte-panda-mu-lite-carrier-board","customUrl":"run-gpu-on-latte-panda-mu-lite-carrier-board","youtubeLink":"https://www.youtube.com/embed/iXYsRK_gqTA","suggestedArticles":[{"title":"A palm-size IO board for Raspberry Pi CM5","url":"https://smarthomecircle.com/raspberry-pi-cm5-small-io-board-hands-on"},{"title":"Radxa Cubie A5E Hands-On: The Budget NVMe SBC","url":"https://smarthomecircle.com/radxa-cubie-a5e-review-benchmarks-vs-raspberry-pi"},{"title":"I Built A DIY 10 Inch Server Rack","url":"https://smarthomecircle.com/I-built-a-diy-10-inch-server-rack"}]}},"authorDetails":[{"readingTime":{"text":"2 min read","minutes":1.01,"time":60600,"words":202},"slug":["default"],"fileName":"default.md","name":"Amrut Prabhu","avatar":"/static/images/avatar-small.jpg","avatarBig":"/static/images/avatar-big.jpg","occupation":"","company":"","email":"contactsmarthomecircle@gmail.com","twitter":"https://twitter.com/smarthomecircle","linkedin":"","github":"","youtube":"https://www.youtube.com/@SmartHomeCircle","customUrl":"default","actualUrl":"default","date":null}],"prev":{"title":"My Hands-On with a 7.3″ Color ePaper Display (Seeed Studio reTerminal E1002)","author":"Amrut Prabhu","categories":"","tags":["Dashboard","epaper","ESPHome","Home Assistant","AI"],"photo-credits":null,"applaud-link":"2021/spring-boot-stream-kafka.json","date":"2025-11-06T00:00:00.000Z","draft":false,"autoAds":true,"summary":"Make a beautiful, low-power status board on a 7.3″ color ePaper. My ESP32-S3 tips, SenseCraft presets, and ESPHome LVGL config notes inside","imageUrl":"/static/images/2025/seeed-reterminal-e1002/cover.webp","actualUrl":"2025/seeed-studio-reterminal-e1002-color-epaper-7-3-review","customUrl":"seeed-studio-reterminal-e1002-color-epaper-7-3-review","youtubeLink":"https://www.youtube.com/embed/Nb-NRA7cv1M","suggestedArticles":[{"title":"Seeed Studio Xiao 7.5 inch ePaper Display + ESPHome","url":"https://smarthomecircle.com/seeed-studio-xiao-epaper-dashboard-home-assistant"},{"title":"Local Voice Assistant with ReSpeaker Lite and Home Assistant","url":"https://smarthomecircle.com/local-voice-assistant-with-seeed-studio-respeaker-lite"},{"title":"Control LED Matrix With Home Assistant Like A Pro","url":"https://smarthomecircle.com/how-to-control-8x32-led-matrix-like-a-pro"}],"slug":"seeed-studio-reterminal-e1002-color-epaper-7-3-review"},"next":{"title":"Radxa Cubie A7A Review: Pi-Sized Power With PCIe, NVMe, USB 3.1 Gen2, Thermals \u0026 Real-World Benchmarks","author":"Amrut Prabhu","categories":"","tags":["SBC","radxa","perfromance","cubie","benchmarks"],"photo-credits":null,"applaud-link":"2021/spring-boot-stream-kafka.json","date":"2025-11-20T00:00:00.000Z","draft":false,"autoAds":true,"summary":"I benchmarked the Radxa Cubie A7A (Allwinner A733): thermals, Geekbench, LPDDR5, PCIe NVMe, USB 3.1 Gen2, Whisper/HA, and Pi 5 vs Pi 4 comparisons.","imageUrl":"/static/images/2025/radxa-cubie-a7a/cover.webp","actualUrl":"2025/radxa-cubie-a7a-review-benchmarks-pi-5-comparison","customUrl":"radxa-cubie-a7a-review-benchmarks-pi-5-comparison","youtubeLink":"https://www.youtube.com/embed/3MdcOY9aIn4","suggestedArticles":[{"title":"A palm-size IO board for Raspberry Pi CM5","url":"https://smarthomecircle.com/raspberry-pi-cm5-small-io-board-hands-on"},{"title":"Radxa Cubie A5E Hands-On: The Budget NVMe SBC","url":"https://smarthomecircle.com/radxa-cubie-a5e-review-benchmarks-vs-raspberry-pi"},{"title":"I Built A DIY 10 Inch Server Rack","url":"https://smarthomecircle.com/I-built-a-diy-10-inch-server-rack"}],"slug":"radxa-cubie-a7a-review-benchmarks-pi-5-comparison"}},"__N_SSG":true},"page":"/[slug]","query":{"slug":"run-gpu-on-latte-panda-mu-lite-carrier-board"},"buildId":"si5NwbjYRJRZuz5hjmIr6","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>